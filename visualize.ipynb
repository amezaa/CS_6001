{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import cntk\n",
    "from cntk.io import StreamDef, StreamDefs, MinibatchSource, CBFDeserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frame_height = 120\n",
    "frame_width = 120\n",
    "num_channels = 1\n",
    "sequence_length = 20\n",
    "num_classes = 66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_axis = cntk.Axis('inputAxis')\n",
    "label_axis = cntk.Axis('labelAxis')\n",
    "input_sequence = cntk.layers.SequenceOver[input_axis]\n",
    "label_sequence = cntk.layers.SequenceOver[label_axis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_start = np.zeros(66)\n",
    "sentence_start[64] = 1\n",
    "sentence_start = cntk.Constant(sentence_start, dtype=np.float32)\n",
    "sentence_end_index = 65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./output/label.json', 'r') as jfile:\n",
    "    label_dict = json.load(jfile)\n",
    "    label_dict['BOS'] = 64\n",
    "    label_dict['EOS'] = 65\n",
    "\n",
    "i2w = {label_dict[w]: w for w in label_dict}\n",
    "pairs = sorted([(k, label_dict[k]) for k in label_dict], key=lambda x: x[1])\n",
    "classes = [k[0] for k in pairs][:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cbf_reader(path, is_training, max_samples):\n",
    "    \"\"\"\n",
    "    Returns a MinibatchSource for data at the given path\n",
    "    :param path: Path to a CBF file\n",
    "    :param is_training: Set to true if reader is for training set, else false\n",
    "    :param max_samples: Max no. of samples to read\n",
    "    \"\"\"\n",
    "    deserializer = CBFDeserializer(path, StreamDefs(\n",
    "        label=StreamDef(field='label', shape=num_classes, is_sparse=True),\n",
    "        pixels=StreamDef(field='pixels', shape=num_channels * frame_height * frame_width, is_sparse=False)\n",
    "    ))\n",
    "\n",
    "    return MinibatchSource(deserializer, randomize=is_training, max_samples=max_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_greedy(s2smodel, input_sequence, sentence_start):\n",
    "    @cntk.Function\n",
    "    @cntk.layers.Signature(input_sequence[cntk.layers.Tensor[num_channels, frame_height, frame_width]])\n",
    "    def model_greedy(input_var):\n",
    "        # Subtract previous frame from next frame\n",
    "        s1 = cntk.sequence.slice(input_var, 1, 20)\n",
    "        s2 = cntk.sequence.slice(input_var, 0, 19)\n",
    "        layer_input = s1 - s2\n",
    "        \n",
    "        unfold = cntk.layers.UnfoldFrom(lambda history: s2smodel(history, layer_input) >> cntk.hardmax, length_increase=0.1)\n",
    "        return unfold(initial_state=sentence_start, dynamic_axes_like=input_var)\n",
    "\n",
    "    return model_greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_sparse_to_dense(vocab_dim, input_sequence):\n",
    "    \"\"\"\n",
    "    Dummy function for printing the input sequence.\n",
    "    \"\"\"\n",
    "    i = cntk.Constant(np.eye(vocab_dim))\n",
    "\n",
    "    @cntk.Function\n",
    "    @cntk.layers.Signature(input_sequence[cntk.layers.SparseTensor[vocab_dim]])\n",
    "    def no_op(input_var):\n",
    "        return cntk.times(input_var, i)\n",
    "\n",
    "    return no_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def format_sequences(sequences, i2w):\n",
    "    \"\"\"\n",
    "    Given a tensor and vocabulary, print the output\n",
    "    \"\"\"\n",
    "    return [' '.join([i2w[np.argmax(w)]]) for w in sequences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display(frame):\n",
    "    plt.imshow(frame, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stitch(output):\n",
    "    filters, count, width, height = output.shape\n",
    "    img = np.empty((height * filters, width * count))\n",
    "    \n",
    "    for i in range(filters):\n",
    "        for j in range(count):\n",
    "            sub = output[i][j]\n",
    "            img[i*height: i*height + height, j*width: j*width + width] = sub\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2\n",
    "    for i,j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment='center',\n",
    "                color='white' if cm[i, j] > thresh else 'black')\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(model_greedy, reader, sparse_to_dense, i2w):\n",
    "    # List of (target, prediction)\n",
    "    result = []\n",
    "    while True:\n",
    "        mb = reader.next_minibatch(1)\n",
    "        if not mb:\n",
    "            break\n",
    "\n",
    "        label = sparse_to_dense(mb[reader.streams.label])[0][1]\n",
    "        outputs = model_greedy(mb[reader.streams.pixels])       \n",
    "        result.append((label, outputs[-1]))\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create output directory if it doesn't already exist\n",
    "result_dir = './results'\n",
    "img_dir = './images'\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "    \n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prefixes = ['']\n",
    "for i in range(10):\n",
    "    prefixes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sparse_to_dense = create_sparse_to_dense(num_classes, input_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for prefix in prefixes:\n",
    "    test_file = r'.\\dataset\\sequential\\test{}.cbf'.format(prefix)\n",
    "    model_path = r'.\\models\\run{}\\final_model.dnn'.format(prefix)\n",
    "    \n",
    "    # Load the trained model\n",
    "    model = cntk.load_model(model_path)\n",
    "    greedy_model = create_model_greedy(model, input_sequence, sentence_start)\n",
    "    \n",
    "    # Create a reader (test set)\n",
    "    reader = cbf_reader(test_file, is_training=False, max_samples=cntk.io.FULL_DATA_SWEEP)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    result = test(greedy_model, reader, sparse_to_dense, i2w)\n",
    "    indices = [(str(t.argmax()), str(p.argmax())) for t, p in result]\n",
    "    \n",
    "    # Save the results for later\n",
    "    with open(os.path.join(result_dir, 'result{}.json'.format(prefix)), 'w') as out_file:\n",
    "        json.dump(indices, out_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a reader (test set)\n",
    "reader = cbf_reader(test_file, is_training=False, max_samples=cntk.io.FULL_DATA_SWEEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\cntk-py35\\lib\\site-packages\\cntk\\tensor.py:236: UserWarning: converting Value object to CSR format might be slow\n",
      "  warnings.warn('converting Value object to CSR format might be slow')\n",
      "C:\\local\\Anaconda3-4.1.1-Windows-x86_64\\envs\\cntk-py35\\lib\\site-packages\\cntk\\tensor.py:244: UserWarning: Cannot convert a sparse NDArrayView or Value object with shape (1, 3, 66) of rank > 2 to a scipy.csr matrix. Returning dense data.\n",
      "  ' Returning dense data.' % str(dense_data.shape))\n"
     ]
    }
   ],
   "source": [
    "# Read a single sample and its target label\n",
    "mb = reader.next_minibatch(1)\n",
    "\n",
    "frames = []\n",
    "seq = mb[reader.streams.pixels].as_sequences()[0]\n",
    "for i in range(len(seq)):\n",
    "    frames.append(seq[i].reshape((num_channels, frame_height, frame_width)))\n",
    "\n",
    "label = mb[reader.streams.label].asarray()[0][1].argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected 1, got 1\n"
     ]
    }
   ],
   "source": [
    "out = greedy_model.eval([frames])\n",
    "print('Expected {}, got {}'.format(label, out[-1].argmax()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nodes = cntk.logging.get_node_outputs(greedy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visualize outputs of convolution and pooling layers on sample\n",
    "for node in nodes:\n",
    "    if not ('conv' in node.name or 'pool' in node.name):\n",
    "        continue\n",
    "        \n",
    "    layer = cntk.combine([greedy_model.find_by_name(node.name)])\n",
    "    out = layer.eval([frames])\n",
    "    \n",
    "    one = np.array([out[i][0] for i in range(len(out))])\n",
    "    img = stitch(one)\n",
    "    plt.imsave(os.path.join(img_dir, '{}_{}.png'.format(prefix, node.name)), img, cmap='gray')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
